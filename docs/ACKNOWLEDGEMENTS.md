# Acknowledgements

* Georgi Gerganov and his [GGML](https://github.com/ggerganov/ggml)
  project shining a spotlight on community-based enablement and
  inspiring so many other projects.

* Andrej Karpathy and his
  [llama2.c](https://github.com/karpathy/llama2.c) project.  So many
  great (and simple!) ideas in llama2.c that we have directly adopted
  (both ideas and code) from his repo.  You can never go wrong by
  following Andrej's work.

* Bert Maher and his [llama2.so](https://github.com/bertmaher/llama2.so),
  which built on Andrej's llama2.c and closed the loop on Llama models with
  AOTInductor.

* Christian Puhrsch, Horace He, Joe Isaacson and many more for their
  many contributions in Accelerating GenAI models in the *"Anything,
  Fast!"* pytorch.org blogs, and, in particular, Horace He for [GPT,
  Fast!](https://github.com/pytorch-labs/gpt-fast), which we have
  directly adopted (both ideas and code) from his repo.

* Bert Maher, Scott Wolchok, Bin Bao, Chen Yang, Huamin Li and Mu-Chu
  Li for great collaborations in building AOTInductor for CPU including
  for [nanoGPT](https://github.com/karpathy/nanoGPT).

* Mobius Labs as the authors of the HQQ quantization algorithms
  included in this distribution.
