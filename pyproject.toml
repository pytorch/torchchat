# ---- All project specifications ---- #
[project]
name = "torchat"
description = "Run PyTorch LLMs locally on servers, desktop and mobile"
readme = "README.md"
requires-python = ">=3.8"
license = {file = "LICENSE"}
authors = [
    { name = "PyTorch Team", email = "packages@pytorch.org" },
]
keywords = ["pytorch", "local", "llm"]
dependencies = [
    # PyTorch ecosystem
    "torch",
    "torchao",
    "executorch",

    # Hugging Face download
    "huggingface_hub",

    # GGUF import
    "gguf",

    # Tiktoken tokenizer for Llama 3 and other advanced models
    "tiktoken",

    # Miscellaneous
    "snakeviz",
    "sentencepiece",
    "numpy",
    "lm-eval",
    "blobfile",
]
dynamic = ["version"]

[project.urls]
GitHub = "https://github.com/pytorch/torchat"
Documentation = "https://github.com/pytorch/torchat"
Issues = "https://github.com/pytorch/torchat/issues"

[project.scripts]
torchat = "torchat._cli.torchat:main"

[project.optional-dependencies]
dev = [
    "pre-commit",
    "pytest",
    "pytest-cov",
    "pytest-mock",
    "pytest-integration",
]

[tool.setuptools.dynamic]
version = {attr = "torchat.__version__"}


# ---- Explicit project build information ---- #
[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = [""]
include = ["*.py,", "runner*", "scripts*", "tokenizer*", "utils*"]
