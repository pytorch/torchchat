name: Compile main

on:
  push:
    branches:
      - main
  pull_request:
  workflow_dispatch:

jobs:
  gguf-util-test:
    strategy:
      matrix:
        runner: [macos-14]
    runs-on: ${{matrix.runner}}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Print machine info
        run: |
          uname -a
          if [ $(uname -s) == Darwin ]; then
            sysctl machdep.cpu.brand_string
            sysctl machdep.cpu.core_count
          fi
      - name: Install requirements
        run: |
          echo "Intalling pip packages"
          pip install gguf
          pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
          pip install -r requirements.txt

          git clone https://github.com/ggerganov/llama.cpp.git
          pushd llama.cpp
          make
          popd

      - name: Download GGUF files
        run: |
          mkdir gguf_files
          wget -O gguf_files/llama-2-7b.Q4_0.gguf "https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q4_0.gguf?download=true"
          ./llama.cpp/quantize --allow-requantize gguf_files/llama-2-7b.Q4_0.gguf gguf_files/llama-2-7b.Q4_0.requant_F32.gguf F32

      - name: Load files
        run: |
          touch test.py
          echo "from build.gguf_util import test_by_to_float" >> test.py
          echo "test_by_to_float(\"gguf_files/llama-2-7b.Q4_0.gguf\", \"gguf_files/llama-2-7b.Q4_0.requant_F32.gguf\")" >> test.py
          cat test.py
          python test.py

          echo "Tests complete."
