name: Compile main

on:
  push:
    branches:
      - main
    paths:
      - .github/workflows/compile.yml
  pull_request:
  workflow_dispatch:

jobs:
  do_compile:
    runs-on: macos-12
    # runs-on: self-hosted
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Compile and run
        # shell: arch -arch arm64 zsh {0}
        run: 
          uname -a
          sysctl machdep.cpu.brand_string
          sysctl machdep.cpu.core_count
	  pip install -r requirements.txt
	  mkdir -p checkpoints/stories15M
	  cd checkpoints/stories15M
	  wget https://huggingface.co/karpathy/tinyllamas/raw/main/stories15M.pt
	  wget https://huggingface.co/karpathy/tinyllamas/raw/main/stories15M.bin
	  wget https://github.com/karpathy/llama2.c/blob/master/tokenizer.model
	  cd ../..
	  export MODEL_REPO=stories15M
	  python aoti_export.py --checkpoint_path checkpoints/$MODEL_REPO/ --output-path ./${MODEL_REPO}.so
	  python generate.py --checkpoint_path checkpoints/$MODEL_REPO/ --temperature 0 |& tee output_eager
	  python generate.py --compile --checkpoint_path checkpoints/$MODEL_REPO/ --temperature 0 |& tee output_compiled
	  python generate.py --checkpoint_path checkpoints/$MODEL_REPO/ --temperature 0 --dso ./${MODEL_REPO}.so |& tee output_aoti
	  echo "******************************************"
	  echo "********* EAGER vs TORCH.COMPILE *********"
	  echo "******************************************"
	  diff output_eager output_compiled
	  echo "******************************************"
	  echo "********* EAGER vs AOT INDUCTOR  *********
	  echo "******************************************"
	  diff output_eager output_aoti
	  
