# Chat with LLMs Everywhere

This directory hosts examples of how to leverage model inference.

* OpenAI API Integration: `openai_api.py`
* Streamlit UI: `browser.py`
* Localhost Flask Server (OpenAI API): `server.py`
