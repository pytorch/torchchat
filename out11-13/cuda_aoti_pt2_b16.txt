python3 torchchat.py export llama3.1 --quantize '{"precision": {"dtype":"bfloat16"}, "executor":{"accelerator":"cuda"}}' --output-aoti-package-path /tmp/model16.pt2
OMP_NUM_THREADS=16 numactl --cpunodebind=0 --membind=0 python3 torchchat.py generate llama3.1 --aoti-package-path /tmp/model16.pt2 --prompt "Once upon a time," --max-new-tokens 200 --device cuda --num-samples 3
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
python3 torchchat.py export llama3.1 --quantize '{"precision": {"dtype":"bfloat16"}, "executor":{"accelerator":"cuda"}}' --output-aoti-package-path /tmp/model16.pt2
Note: NumExpr detected 22 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
NumExpr defaulting to 16 threads.
PyTorch version 2.6.0.dev20241002+cu121 available.
W1113 19:12:50.443086 2663633 site-packages/torch/_export/__init__.py:225] +============================+
W1113 19:12:50.443580 2663633 site-packages/torch/_export/__init__.py:226] |     !!!   WARNING   !!!    |
W1113 19:12:50.443778 2663633 site-packages/torch/_export/__init__.py:227] +============================+
W1113 19:12:50.443982 2663633 site-packages/torch/_export/__init__.py:228] torch._export.aot_compile() is being deprecated, please switch to directly calling torch._inductor.aoti_compile_and_package(torch.export.export()) instead.
Using device=cuda
Setting max_seq_length to 300 for DSO export.
Loading model...
Time to load model: 6.44 seconds
Quantizing the model with: {'precision': {'dtype': 'bfloat16'}, 'executor': {'accelerator': 'cuda'}}
Time to quantize model: 0.01 seconds
-----------------------------------------------------------
Exporting model using AOT Inductor to /tmp/model16.pt2
The generated packaged model can be found at: /tmp/model16.pt2
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
OMP_NUM_THREADS=16 numactl --cpunodebind=0 --membind=0 python3 torchchat.py generate llama3.1 --aoti-package-path /tmp/model16.pt2 --prompt "Once upon a time," --max-new-tokens 200 --device cuda --num-samples 3
PyTorch version 2.6.0.dev20241002+cu121 available.
lm_eval is not installed, GPTQ may not be usable
Warning: checkpoint path ignored because an exported DSO or PTE path was specified
Warning: checkpoint path ignored because an exported DSO or PTE path was specified
Using device=cuda NVIDIA PG509-210
Loading model...
Time to load model: 5.59 seconds
-----------------------------------------------------------
Once upon a time, there was a magical kingdom ruled by a just and fair queen named Sophia. The kingdom was known for its lush green forests, sparkling rivers, and rolling hills. The people of the kingdom lived in harmony with nature and with each other.
One day, a dark and mysterious force began to spread throughout the kingdom. It was a strange and eerie phenomenon that caused the once-vibrant colors of the natural world to fade and lose their brilliance. The forests grew dull and gray, the rivers became murky and stagnant, and the hills turned a sickly shade of brown.
The people of the kingdom were frightened and confused by this development. They didn't know what was causing it or how to stop it. Sophia, the wise and compassionate queen, called for the wise men and women of the land to gather and try to find a solution.
After much discussion and contemplation, the wise men and women decided to seek out the counsel of the ancient trees that stood tall in the heart of the forest.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 1: 2.6466 sec total                 
Time to first token: 0.2653 sec with sequential prefill.                

      Total throughput: 75.5673 tokens/sec, 0.0132 s/token                 
First token throughput: 3.7700 tokens/sec, 0.2653 s/token                 
 Next token throughput: 83.5644 tokens/sec, 0.0120 s/token                     

Bandwidth achieved: 0.00 GB/s
*** This first iteration will include cold start effects for dynamic import, hardware caches. ***

========================================

Once upon a time, I wrote a short story called "The Day My Cat Was Put in a Sack" and posted it online. I was surprised by how many people submitted comments about what a great story it was and how well I'd written it. Later, I learned that one of the commenters was an English teacher in high school, who'd assigned the story to her students.
That was a pleasant surprise, and I was thrilled to think that my little short story had been of use to her students. Since then, I've tried to write more short stories that might be useful to teachers and students alike.
One of the best things about short stories is that they can be used in the classroom to teach a wide range of skills, from reading comprehension to creative writing. And since they're relatively short, they're easy to assign as homework or reading assignments, even for students who are struggling.
But short stories can also be a great way to engage students who are more advanced, providing a rich source of
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 2: 2.5317 sec total                 
Time to first token: 0.0585 sec with sequential prefill.                

      Total throughput: 78.9969 tokens/sec, 0.0127 s/token                 
First token throughput: 17.0982 tokens/sec, 0.0585 s/token                 
 Next token throughput: 80.4607 tokens/sec, 0.0124 s/token                     

Bandwidth achieved: 0.00 GB/s

========================================

Once upon a time, in a world not so very different from our own, there lived a young woman named Jane. Jane was a hard worker, dedicated to her job at a small bookstore in a quiet town. She loved nothing more than getting lost in a good book, and she spent most of her free time reading whatever caught her fancy.
One day, while shelving books, Jane stumbled upon an old, mysterious tome hidden away on a dusty shelf. The book was bound in black leather, adorned with strange symbols etched into the cover. As she picked it up, she felt an inexplicable shiver run down her spine.
Curiosity got the better of her, and Jane opened the book, releasing a faint whisper of incense into the air. The pages crackled as she turned them, revealing words that seemed to dance across the paper. The text was written in a language she couldn't quite decipher, but something about it resonated deep within her.
As she delved deeper into the book,
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 3: 2.4254 sec total                 
Time to first token: 0.0587 sec with sequential prefill.                

      Total throughput: 82.4603 tokens/sec, 0.0121 s/token                 
First token throughput: 17.0414 tokens/sec, 0.0587 s/token                 
 Next token throughput: 84.0823 tokens/sec, 0.0119 s/token                     

Bandwidth achieved: 0.00 GB/s

========================================


      Average tokens/sec (total): 79.01                 
Average tokens/sec (first token): 12.64                 
Average tokens/sec (next tokens): 82.70 
                
Memory used: 0.05 GB
