python3 torchchat.py export llama3.1 --quantize '{"linear:int8": {"groupsize": 0}, "precision": {"dtype":"bfloat16"}, "executor":{"accelerator":"cuda"}}' --output-dso-path /tmp/model8.so
OMP_NUM_THREADS=16 numactl --cpunodebind=0 --membind=0 python3 torchchat.py generate llama3.1 --dso-path /tmp/model8.so --prompt "Once upon a time," --max-new-tokens 200 --device cuda --num-samples 3
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
python3 torchchat.py export llama3.1 --quantize '{"linear:int8": {"groupsize": 0}, "precision": {"dtype":"bfloat16"}, "executor":{"accelerator":"cuda"}}' --output-dso-path /tmp/model8.so
Note: NumExpr detected 22 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
NumExpr defaulting to 16 threads.
PyTorch version 2.6.0.dev20241002+cu121 available.
W1113 19:04:26.203908 2539376 site-packages/torch/_export/__init__.py:225] +============================+
W1113 19:04:26.204442 2539376 site-packages/torch/_export/__init__.py:226] |     !!!   WARNING   !!!    |
W1113 19:04:26.204647 2539376 site-packages/torch/_export/__init__.py:227] +============================+
W1113 19:04:26.204843 2539376 site-packages/torch/_export/__init__.py:228] torch._export.aot_compile() is being deprecated, please switch to directly calling torch._inductor.aoti_compile_and_package(torch.export.export()) instead.
Using device=cuda
Setting max_seq_length to 300 for DSO export.
Loading model...
Time to load model: 6.75 seconds
Quantizing the model with: {'linear:int8': {'groupsize': 0}, 'precision': {'dtype': 'bfloat16'}, 'executor': {'accelerator': 'cuda'}}
Time to quantize model: 0.39 seconds
-----------------------------------------------------------
Exporting model using AOT Inductor to /tmp/model8.so
WARNING!! The path of compiling a dso is deprecated. Please use --output-aoti-package-path to create a .pt2 artifact instead.
The generated packaged model can be found at: /tmp/model8.so
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
OMP_NUM_THREADS=16 numactl --cpunodebind=0 --membind=0 python3 torchchat.py generate llama3.1 --dso-path /tmp/model8.so --prompt "Once upon a time," --max-new-tokens 200 --device cuda --num-samples 3
PyTorch version 2.6.0.dev20241002+cu121 available.
lm_eval is not installed, GPTQ may not be usable
Warning: checkpoint path ignored because an exported DSO or PTE path was specified
Warning: checkpoint path ignored because an exported DSO or PTE path was specified
Using device=cuda NVIDIA PG509-210
Loading model...
Time to load model: 7.33 seconds
-----------------------------------------------------------
Once upon a time, I found myself in a bind with my company’s HR department. I had made a workplace mistake that I was certain would not be swept under the rug. The mistake was something that no one else would have done, and I felt a bit anxious about the outcome of the entire situation. I expressed my anxiety to a friend, who suggested that I use a technique that involves imagining the meeting and practicing responses to any questions that the HR representative might ask. I was skeptical at first, but I decided to give it a try. I spent several hours imagining the meeting and practicing responses to questions that the HR representative might ask. To my surprise, I felt more confident and prepared going into the meeting, and I walked out of it feeling like I had a clear understanding of the issues and a clear plan for moving forward.
In that moment, I realized the power of mental projection and visualization in preparation for high-stakes situations. This technique can be applied to a wide range of situations, from business meetings
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 1: 1.7958 sec total                 
Time to first token: 0.1859 sec with sequential prefill.                

      Total throughput: 111.3736 tokens/sec, 0.0090 s/token                 
First token throughput: 5.3795 tokens/sec, 0.1859 s/token                 
 Next token throughput: 123.6126 tokens/sec, 0.0081 s/token                     

Bandwidth achieved: 0.00 GB/s
*** This first iteration will include cold start effects for dynamic import, hardware caches. ***

========================================

Once upon a time, in a far-off galaxy, there existed a planet called Zara-Xylophia-IV. This planet was home to a peculiar species of beings known as the Zara-Xylophians. They were a curious race, with bodies composed of a translucent, crystalline material that reflected the colors of the surrounding environment.
The Zara-Xylophians were known for their remarkable gift – they could absorb and store the memories of others through a process called "echo-resonance." This allowed them to learn from one another's experiences and develop a deep understanding of the universe.
One day, a young Zara-Xylophian named Lyra stumbled upon an ancient artifact buried deep within the planet's core. The artifact, known as the "Echo-keeper," emitted a distinctive hum that resonated with Lyra's own echo-resonance.
As soon as Lyra touched the Echo-keeper, she felt an explosion of memories flood her mind. She saw visions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 2: 1.6096 sec total                 
Time to first token: 0.0386 sec with sequential prefill.                

      Total throughput: 124.2579 tokens/sec, 0.0080 s/token                 
First token throughput: 25.8742 tokens/sec, 0.0386 s/token                 
 Next token throughput: 126.6784 tokens/sec, 0.0079 s/token                     

Bandwidth achieved: 0.00 GB/s

========================================

Once upon a time, in a world not so different from our own, there lived a man named Jack. Jack was a bit of an oddity in his community, for he was a master of the ancient art of...well, he wasn't quite sure what it was, but he was good at it. He called it "the knack," and he'd been practicing it for years.
The knack, as Jack understood it, involved the subtle manipulation of everyday objects to achieve unexpected and often bizarre results. He could make a spoon spin on its own, a flower bloom in mid-air, and a perfectly ordinary rock levitate above the ground. It was a bit like magic, but without the fancy dress or the wand.
Jack's knack was a bit of a mystery to everyone around him, including himself. He couldn't quite explain how he did it, and he often found himself struggling to replicate the effects he'd achieved by accident. But he was determined to master the knack, and to use it for the
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                
Generated 199 tokens                 
Time for inference 3: 1.6183 sec total                 
Time to first token: 0.0388 sec with sequential prefill.                

      Total throughput: 123.5837 tokens/sec, 0.0081 s/token                 
First token throughput: 25.7681 tokens/sec, 0.0388 s/token                 
 Next token throughput: 125.9869 tokens/sec, 0.0079 s/token                     

Bandwidth achieved: 0.00 GB/s

========================================


      Average tokens/sec (total): 119.74                 
Average tokens/sec (first token): 19.01                 
Average tokens/sec (next tokens): 125.43 
                
Memory used: 0.05 GB
